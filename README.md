# Linear-Regression-Wars-Sklearn-vs-TensorFlow-vs-XGBoost-vs-LightGBM-vs-CatBoost-vs-PyTorch
![image](https://github.com/user-attachments/assets/95aacd83-056b-418b-a4a3-551924fa3f6b)

# What is Linear Regression?
Linear Regression is one of the simplest and most widely used algorithms in machine learning. It is used for predicting a continuous value based on the relationship between independent (input) variables and a dependent (output) variable.

ðŸ“ˆ Equation of Simple Linear Regression:
y = mx+b
Where:
y is the predicted value (dependent variable)
x is the input feature (independent variable)
m is the slope (coefficient)
b is the y-intercept


- âœ… **Scikit-learn** â†’ Simplest implementation with LinearRegression() for classic ML.
- âœ… **TensorFlow (Keras)** â†’ Deep learning approach using gradient descent.
- âœ… **Statsmodels** â†’ Detailed statistical summaries (p-values, R-squared).
- âœ… **XGBoost** â†’ Boosted trees with linear models as base learners.
- âœ… **LightGBM** â†’ Faster gradient boosting with linear tree splits.
- âœ… **CatBoost** â†’ Handles categorical features natively in regression.
- âœ… **PyTorch** â†’ Customizable neural-network-style regression.

Bonus:

**Scikit-learn:** Best for quick prototyping.
**Statsmodels:** Best for statistical rigor.
**TF/PyTorch:** Best for scalability & customization.
**XGBoost/LightGBM/CatBoost:** Best for hybrid (tree + linear) performance.


